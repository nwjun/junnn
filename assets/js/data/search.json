[ { "title": "Lessons Learned from Social Engagement", "url": "/junnn/posts/Social-Engagement-4/", "categories": "Social Engagement", "tags": "social-engagement", "date": "2022-06-12 00:18:21 +0000", "snippet": "Lessons LearnedI have learned a lot from this course. First, I learned to cooperate with others. During the event, we have to discuss and generate ideas together to make a successful event. Through the discussion, I learned to listen to others’ ideas and voice my opinion. Before this, I was a shy person and was afraid to provide my ideas. However, in this event, the team members are kind and helpful. They won’t criticize or judge my ideas even if they are not applicable sometimes. Thanks to them for this.Photo by Jason Goodman on UnsplashBesides, I also learned to manage time wisely. The schedule and tasks for this semester are quite packed and heavy. So to finish all the tasks given, I was forced to spend lesser time on leisure and more time focusing on the tasks. I learned to jot down important meetings and tasks in my notebook so that I don’t miss out on anything.Photo by goumbik on UnsplashOther than that, I also learned to not give up on obstacles. Problems can be solved. Even if it is hard, we can just break them down and solve them little by little (or in techy terms, divide and conquer).Next, I participated in the last module, Digital Advocacy. In that talk, the mentors talked about the importance of social media in leveraging our voice as supporters and activists. Hashtags and engaging content in social media can influent others and should be used wisely.All the modules have ended and I have retrospected what I did during the pre-event and during the event. I realize there are things that I could do better. I should’ve communicated more with other departments to ensure that there was no miscommunication. This happened because I didn’t explain the requests more clearly and I thought they understood my requests but turned out not. This had slowed down the progress when developing the website as they were unable to provide the content I requested on time. But after communication, we cleared all the confusion and we were able to collaborate.Besides, I have to be more patient when making a request. I should control my sentiment better even if they didn’t send me the contents I need on time. The situation would be not that bad if I had controlled my temper.2 more weeks till the closing ceremony of this event, good job everyone! Let’s keep the pace till the end!" }, { "title": "Chord Diagram", "url": "/junnn/posts/R/", "categories": "Data Science", "tags": "r, data science, sentiment-analysis", "date": "2022-06-09 22:52:15 +0000", "snippet": "What is a Chord DiagramA chord diagram shows flows between a set of entities. It displays entities all around a circle and connects entities with arcs.Chord diagrams are attractive and they visualize weighted relationships between several entities. There are a few slightly modified outputs and the way to read them: • Flow. Two ways to represent it: ◦ One asymmetric arc per pair ◦ Two arcs per pair • Bipartite: Nodes are grouped in a few categories. Connections go between categories but not within categories.There are some common mistakes we should avoid: • The order of the group around the circle is critical. Reduce the number of arc crossings as much as possible. • The figure is unreadable due to mental clutter. Weak connections should be avoided. • Chord diagrams are extremely difficult to comprehend. When presenting it, give audience plenty of explanation. It is recommended that the graphic be broken down and presented in stages.ExampleHere’s the example of generating a chord diagram by using circlize packages in R :Creating a tibble that shows the sentiment of each part of the tidy_text.# Mood Ringgrid.col = c(&quot;1&quot; = &quot;#51BBFE&quot;, &quot;2&quot; = &quot;#8FF7A7&quot;, &quot;3&quot; = &quot;#F4E76E&quot;, &quot;anger&quot; = &quot;grey&quot;, &quot;anticipation&quot; = &quot;grey&quot;, &quot;disgust&quot; = &quot;grey&quot;, &quot;fear&quot; = &quot;grey&quot;, &quot;joy&quot; = &quot;grey&quot;, &quot;sadness&quot; = &quot;grey&quot;, &quot;surprise&quot; = &quot;grey&quot;, &quot;trust&quot; = &quot;grey&quot;)part_mood = tidy_text %&amp;gt;% inner_join(get_sentiments(&quot;nrc&quot;))%&amp;gt;% filter(!sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&amp;gt;% count(sentiment, part) %&amp;gt;% group_by(part, sentiment) %&amp;gt;% summarise(sentiment_sum = sum(n)) %&amp;gt;% ungroup()Mood in Every PartPlotting the graph:circos.clear()circos.par(gap.after = c(rep(5, length(unique(part_mood[[1]])) - 1 ), 15, rep(5, length(unique(part_mood[[2]])) - 1 ), 15))chordDiagram(part_mood, grid.col = grid.col, transparency = .2)title(&quot;Relationship Between Mood and Part&quot;)Relationship between Mood and Part These codes are extracted from one of my project, Sentiment Analysis of 1984 Book by George OrwellReferencesHealy, Y. H. A. C. (n.d.). Chord diagram. From Data to Viz.    https://www.data-to-viz.com/graph/chord.htmlHoltz, Y. (n.d.). Advanced chord diagram with R and circlize. R Graph Gallery.    https://r-graph-gallery.com/123-circular-plot-circlize-package-2.html" }, { "title": "Relation with the Community", "url": "/junnn/posts/Social-Engagement-3/", "categories": "Social Engagement", "tags": "social-engagement", "date": "2022-06-01 10:19:21 +0000", "snippet": "Relation with the CommunityWe are grateful to have such big support from youngsters to participate in our programs. Up to today, we had held 3 programs, namely “Digital Privacy”, “Digital Opportunity” and “Digital Security”.Digital Privacy introduces participants to the malicious software so that they can protect themselves, especially during this time when exploitation of users’ privacy is at an all-time high.Digital Opportunity exposes participants to the algorithms in our daily life and gives them a chance to design their ones in groups.The third module, Digital Security teaches participants to protect themselves from online fraud and different types of scams such as financial scams, donation scams, lottery scams and charity scams.As the publicity team, we also posted posters and videos to attract participants from different faculties. I learned to put myself in others’ shoes when writing the advertising content as I have to think about what users want to take away from this event and what kind of content attracts them. Even a small post takes time to be refined and refined to make sure it is nearly perfect for us. (It’s impossible to be perfect! :&amp;gt; )I wish I could join the program but unfortunately, I have another important event on the same day as our event. But from what I heard from the attendees, they learned a lot of knowledge from our event and they don’t regret joining our event. Some of them don’t have the opportunity to know more about the technical stuff but this event provides a platform to expose them to technologies. Besides, they also feedback that they have made some friends as they were split into small groups for discussion. Kudos to the Module Department for planning them and Meta for providing the materials.Photo by John Cameron on UnsplashI’m very happy to hear their feedback and this makes me feel a sense of satisfaction as I have contributed myself to making our society more knowledgable.Through this community project, I really learn a lot of things that cannot be learned through reading or attending classes. Communication skills and time management are the most important lesson I have learned. I’ll elaborate more about it in the next post, so stay tuned!" }, { "title": "Execution of the Project", "url": "/junnn/posts/Social-Engagement-2/", "categories": "Social Engagement", "tags": "social-engagement", "date": "2022-05-13 10:19:21 +0000", "snippet": "Execution of the ProjectFinally, our proposal has been approved! We also chose the final website design by voting with everyone on the team. Then, we split the task among our publicity team so that each of us can contribute together.Task DistributionSwee Nien, Wei Xin and I are responsible for developing the website and the rest will be handling the social media.Our development of the website started by distributing the task. Each of us will do different pages. My task is to develop the website for “event”, “gallery”, “leaderboards” and “FAQ”.TeamworkStarting last Friday, I started to do my part. The hardest page is “event” and the others are quite easy. One of the modules of the “event” page is the most challenging one as it allows users to switch between event modules and it will show different content based on what users selected. A lot of things to consider when building the component. The responsive layout is very tedious as we have to adjust it to common phone layouts to ensure every user will have the best user experience when using the website and I have to make sure the QR code, timetable, mindmap and infographic are all at a good place.I think the members of our team are very helpful. We always back each other up. When I faced difficulties in developing, I asked for help from Wei Xin and he was very helpful in helping to solve the problems. Since we needed the content and pictures from the other department, we first put some dummy data into the website. After they finalize their content, they will pass the data to us and we will put them on the website. When Swee Nien faced problems, I also helped him by sharing my experience with him and at last, we were able to solve them.Photo by Hannah Busing from UnsplashThoughtsI am quite satisfied with our development pace as we only started to do it for a week and the progress is already about 70%. I also appreciate this opportunity for me to practice website development with React." }, { "title": "Sentiment Analysis of 1984 Book by George Orwell", "url": "/junnn/posts/Text-Analysis-with-R/", "categories": "Data Science", "tags": "r, data science, sentiment-analysis", "date": "2022-05-10 02:52:15 +0000", "snippet": "Sentiment Analysis of 1984 Book by George OrwellToday we’ll analyse the 1984 book written by George Orwell using R. 1984 is a dystopian social science fiction novel and it was published on 8 June 1949. It has 8 chapters for Part 1, 9 for Part 2 and 6 for Part 3. 3 of the main characters are Winston Smith, Julia and O’Brien. To know more about the plot, read WikipediaTable of Contents Goals Importing Library Downloading Data Analysing data Word Cloud Sentiment Scores Words to Express Different Emotions and Sentiments Words Contributed to Sentiment Scores by Parts Mood Ring Polar Sentiment Preceded by NOT Negation Bigram Network Back to Goals Conclusion ResourcesGoalsThe problems we would like to discover are: What are the most frequent words used? Which are the positive and negative words prevalent in his book? What are the overall sentiments expressed in his book? Which are the top words used to describe different emotions?Importing LibraryHere we will import all necessary libraries into the environment.The libraries we will be using: Library Function Example rvest For web scraping   magrittr For chaning commands %&amp;gt;% purr Toolkit for functions and vectors map() dplyr For data manipulation mutate(), select(), filter(), summarise(), arrange() tidyr Help creating standard and tidy data unnest(), seperate(), extract(), unite(), complete(), fill() ggplot2 For creating graph   tm For text mining   wordcloud For plotting word cloud   tidytext Text mining tool that includes a lot of required packages get_sentiments() circlize for plotting circular graph   igraph For plotting graph   ggraph Extension of ggplot2 to support relational data structures such as networks, graphs and trees   library(rvest)library(magrittr)library(purrr)library(dplyr)library(tidyr)library(ggplot2)library(tm)library(wordcloud)library(circlize)library(tidytext)library(reshape2)library(igraph)library(ggraph) %&amp;gt;% forward a value of a result of an expression into the next functionDownloading DataWhat’s the most important thing in data science? DATA! To get the full text of 1984, I downloaded it from this website. Using inspection tool, you will notice that the url for each chapter has the form of http://www.george-orwell.org/1984/{no_of_chapter} so we can scrape the data by using rvest library. Here, we will save the text according to chapter and part.# Scrape 1984 textpart = 1chap = 1part_break = data.frame( chap = c(8, 9, 6))for (x in 0:22){ file = paste(&#39;part&#39;, part, &#39;_&#39;, chap, &quot;.txt&quot;,sep=&quot;&quot;) link = paste(&quot;http://www.george-orwell.org/1984/&quot;,toString(x),&quot;.html&quot;, sep=&quot;&quot;) text = read_html(link) %&amp;gt;% html_nodes(&quot;p&quot;) %&amp;gt;% html_text() text = text[4] write(text, file = file, append=TRUE) if (x != 0 &amp;amp; chap == part_break[part, 1]){ part = part + 1 chap = 1 } else{chap = chap + 1}}Then we will get:files_name = list.files(path = &#39;.&#39;, pattern = &quot;part[123]_[1-9].txt&quot;)# [1] &quot;part1_1.txt&quot; &quot;part1_2.txt&quot; &quot;part1_3.txt&quot;# [4] &quot;part1_4.txt&quot; &quot;part1_5.txt&quot; &quot;part1_6.txt&quot;# [7] &quot;part1_7.txt&quot; &quot;part1_8.txt&quot; &quot;part2_1.txt&quot;# [10] &quot;part2_2.txt&quot; &quot;part2_3.txt&quot; &quot;part2_4.txt&quot;# [13] &quot;part2_5.txt&quot; &quot;part2_6.txt&quot; &quot;part2_7.txt&quot;# [16] &quot;part2_8.txt&quot; &quot;part2_9.txt&quot; &quot;part3_1.txt&quot;# [19] &quot;part3_2.txt&quot; &quot;part3_3.txt&quot; &quot;part3_4.txt&quot;# [22] &quot;part3_5.txt&quot; &quot;part3_6.txt&quot;Now, we will make a data frame out of the text files we have downloaded. The data frame should look like this: part chapter text 1 1 Some text # extract part and chapter# part1_1 =&amp;gt; 1_1files_name = list.files(path = &#39;.&#39;, pattern = &quot;part[123]_[1-9].txt&quot;)# empty data framedf = data.frame(matrix(ncol = 3, nrow = 23))colnames(df) = c(&quot;part&quot;, &quot;chapter&quot;, &quot;text&quot;)# put data into data framefor (x in 1:length(files_name)){ file_name = files_name[x] # 1_1 =&amp;gt; [[1,1]] part_chap = gsub(&quot;part|.txt&quot;, &quot;&quot;,file_name) part_chap = strsplit(part_chap,&quot;_&quot;)[[1]] text = readLines(file_name) text = paste(text, collapse=&quot;\\n&quot;) df[x,] = c(part_chap[1], part_chap[2], text)}Analysing dataHere we will be using lexicons to get the sentiment value.Lexicons available: Lexicon Sentiments Output bing Positive, Negative [-1, 1] nrc Positive, Negative, Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust [-1, 1] afinn Positive, Negative [-5, 5] Do note that all these lexicons are based on unigrams. So it can’t process preceeding words that affect the scores of sentiments such as “not”, “never”. Besides, lexicons like bing and nrc give same value for “very happy” and “happy” which should have different sentiments value.We will also use tidy_text library, and the common flow is as below:Word CloudBefore we analyse the text, we will first convert the full text into text corpus. Text corpus is just a collections of documents that has specific attributes and is mostly used in machine learning and NLP.book_text = df$text# create text corpusdocs = Corpus(VectorSource(book_text))# inspect content of document# inspect(docs) # uncomment to inspectWe will be using wordcloud package and before using it, we will first clean the data by removing numbers, punctuation, white space and turn the content into lowercase. Then, we will remove english common stopwords such as is and am as these are not what we want to get from the analysis and they will pollute the data. All of these processes will be implemented by library tm.# Remove punctuations and alphanumeric contentdocs = docs %&amp;gt;% tm_map(removeNumbers) %&amp;gt;% tm_map(removePunctuation) %&amp;gt;% tm_map(stripWhitespace)docs = tm_map(docs, content_transformer(tolower))# remove english common stopwordsdocs = tm_map(docs, removeWords, stopwords(&quot;english&quot;))Then, we will create term document matrix and convert it into a matrix.Term Document Matrix# create term document matrixtdm = TermDocumentMatrix(docs)# define tdm as matrixm = as.matrix(tdm)MatrixNext, perform summation along the row to and convert to data frame with words and their frequency as columns.word_freqs = sort(rowSums(m), decreasing=TRUE)# creating a data frame with words and their frequenciestext_wc_df = data.frame(word=names(word_freqs), freq=word_freqs)text_wc_df = text_wc_df[1:300,]_Text_wc_dfOkay it’s finally the time we plot the word cloud and the corresponding barplot!# plotting word cloudset.seed(1234)wordcloud(words = text_wc_df$word, freq = text_wc_df$freq, min.freq = 1, scale = c(1.8, .5), max.words=200, random.order=FALSE, rot.per=0.3, colors=brewer.pal(8, &quot;Dark2&quot;))# barplotbarplot(text_wc_df[1:10,]$freq, las = 2, names.arg = text_wc_df[1:10,]$word, col = &quot;lightblue&quot;, main=&quot;Most frequent words&quot;, ylab = &quot;Word frequencies&quot;)Most Frequent Word in Word Cloud Most Frequent Word in Bar PlotHere we can notice that the most frequent word is “Winston” whom is the protagonist of 1984 and the word “Obrien”, the 9th frequent word, is the name of an inner leader whom the protagonist trusted wrongly as the opposition leader.Sentiment ScoresNow let’s look at the sentiment scores of the book.We will use the syuzhet library’s method, get_sentiment which will calculate the scores of each sentiments, namely ‘anger’, ‘anticipation’, ‘disgust’, ‘fear’, ‘joy’, ‘negative’, ‘positive’, ‘sadness’, ‘surprise’ and ‘trust’# sentiment value for texttext_sentiment = get_nrc_sentiment((book_text))sentiment_scores = data.frame(colSums(text_sentiment[,]))names(sentiment_scores) = &quot;Score&quot;sentiment_scores = cbind(&quot;sentiment&quot; = rownames(sentiment_scores),sentiment_scores)rownames(sentiment_scores) = NULLPlotting the graph:# Plot for the cumulative sentimentsggplot(data=sentiment_scores,aes(x=sentiment,y=Score))+ geom_bar(aes(fill=sentiment),stat = &quot;identity&quot;)+ theme(legend.position=&quot;none&quot;)+ xlab(&quot;Sentiments&quot;)+ylab(&quot;Scores&quot;)+ ggtitle(&quot;Total sentiment based on scores&quot;)+ theme_minimal()Total Sentiment Based on ScoresWe can know that the book used more negative words than the postives. What surprise me is that the score for trust is quite high, it is one of the top 4 sentiments. I think this happens as the writer describes about how Winston trusted O’brien as the opposition leader.Words to Express Different Emotions and SentimentsHere, we will look at the words used to express different emotions and sentiments in this book. But first we have to tokenise the text by using tidy_text library.df$text = as.character(df$text)tidy_text = df %&amp;gt;% unnest_tokens(word, text)We will use lexicon nrc from syuzhet just as the above and then count the occurence of word and group them by sentiment. Then we select the top 10 words for each sentiment and plot them out.# Words used to express emotionstext_sentiment = tidy_text %&amp;gt;% inner_join(get_sentiments(&quot;nrc&quot;), by=&quot;word&quot;, copy=TRUE)text_sentiment %&amp;gt;% count(word, sentiment, sort=TRUE) %&amp;gt;% group_by(sentiment) %&amp;gt;% top_n(n=10) %&amp;gt;% ungroup() %&amp;gt;% ggplot(aes(x=reorder(word,n), y=n, fill = sentiment)) + geom_col(show.legend = FALSE) + facet_wrap(~sentiment, scales = &quot;free&quot;)+ xlab(&quot;Sentiments&quot;) + ylab(&quot;Scores&quot;)+ ggtitle(&quot;Top words used to express emotions and sentiments&quot;) + coord_flip()Words to Express Emotions and SentimentsIt’s interesting that the word “word” is considered as positive but its plural form “words” is negative. It’s sarcastic that “brother”, “ministry” and “police” are postive words which the readers will definetely considered them as negative words.Words Contributed to Sentiment Scores by PartsHere, we will look at how the sentiment changes as the plot developed. We’ll plot the sentiment scores for each part and the words used.# Sentiment score for every PARTstext_sentiment_part = tidy_text %&amp;gt;% inner_join(get_sentiments(&quot;bing&quot;), by=&quot;word&quot;, copy=TRUE) %&amp;gt;% count(word, sentiment, part, sort=TRUE) %&amp;gt;% group_by(sentiment) %&amp;gt;% ungroup() %&amp;gt;% mutate(word=reorder(word, n)) %&amp;gt;% group_by(part, sentiment) %&amp;gt;% top_n(n=5, wt=n) %&amp;gt;% mutate(part_sentiment=paste0(part, &quot;-&quot;, sentiment)) %&amp;gt;% arrange(part, sentiment, n)text_sentiment_part$part_sentiment = factor(text_sentiment_part$part_sentiment, levels = unique(text_sentiment_part$part_sentiment))text_sentiment_part %&amp;gt;% ggplot(aes(x=word, n, fill=sentiment))+ geom_col(show.legend = FALSE) + facet_wrap(~part_sentiment, scales=&quot;free_y&quot;, ncol=2)+ labs(title = &quot;Sentiment Scores by Parts&quot;, y = &quot;Number of Times of Words Appearead&quot;, x=&quot;Words&quot;) + coord_flip()Sentiment scores by partsWe can conclude that the story get more and more negative and less positive when the plot developed. In Part 3, the writer used a lot of “pain” word in the text and if you’ve actually read the book, Part 3 is writing about how the Party torture the Thought Criminals.Mood RingThis is the graph I personally like the most. This graph explains how each part of the book contributed to every emotion.Same, we will get the sentiments scores by nrc and filter away the 2 columns, namely positive and negative.# Mood Ringgrid.col = c(&quot;1&quot; = &quot;#51BBFE&quot;, &quot;2&quot; = &quot;#8FF7A7&quot;, &quot;3&quot; = &quot;#F4E76E&quot;, &quot;anger&quot; = &quot;grey&quot;, &quot;anticipation&quot; = &quot;grey&quot;, &quot;disgust&quot; = &quot;grey&quot;, &quot;fear&quot; = &quot;grey&quot;, &quot;joy&quot; = &quot;grey&quot;, &quot;sadness&quot; = &quot;grey&quot;, &quot;surprise&quot; = &quot;grey&quot;, &quot;trust&quot; = &quot;grey&quot;)part_mood = tidy_text %&amp;gt;% inner_join(get_sentiments(&quot;nrc&quot;))%&amp;gt;% filter(!sentiment %in% c(&quot;positive&quot;, &quot;negative&quot;)) %&amp;gt;% count(sentiment, part) %&amp;gt;% group_by(part, sentiment) %&amp;gt;% summarise(sentiment_sum = sum(n)) %&amp;gt;% ungroup()Mood in Every PartsNotice that negative and positive columns are removed.Then, we count the sentiment scores by part and plot them out.circos.clear()circos.par(gap.after = c(rep(5, length(unique(part_mood[[1]])) - 1 ), 15, rep(5, length(unique(part_mood[[2]])) - 1 ), 15))chordDiagram(part_mood, grid.col = grid.col, transparency = .2)title(&quot;Relationship Between Mood and Part&quot;)Relationship between Mood and PartWe can clearly see that Part 2 contributes the most to the mood and Part 3 contributes the least. The highest mood scores in Part 2 are trust and anticipation. This makes sense as Part 2 is saying Winston, the protagonist thinks that O’Brien is someone like him, who secretly hates the Party.Polar Sentiment Preceded by NOTWhat we did just now is analyse sentiment by seperating sentence into 1 word. However, in real-life we uses a lot of negation words such as “not”. One-word analysis actually groups them into the opposite sentiment.Now we will look at the most frequent words that are mistakenly grouped into the opposite sentiment.Here, we will use the unnest_tokens from tidytext libray to tokenise 2 words. Then we split them into 2 seperate columns, each with 1 word.text_bigrams = df %&amp;gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n=2)bigrams_seperated = text_bigrams %&amp;gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep= &quot; &quot;)Since we only want 2 consecutive words that starts with “not”, we will filter out the rest.not_words = bigrams_seperated %&amp;gt;% filter(word1 == &quot;not&quot;) %&amp;gt;% inner_join(get_sentiments(&quot;afinn&quot;), by=c(word2 = &quot;word&quot;)) %&amp;gt;% count(word2, value, sort =TRUE) %&amp;gt;% ungroup()Finally, we plot out the top 20 words.not_words %&amp;gt;% mutate(contribution = n*value) %&amp;gt;% arrange(desc(abs(contribution))) %&amp;gt;% head(20) %&amp;gt;% mutate(word2 = reorder(word2, contribution)) %&amp;gt;% ggplot(aes(word2, n*value, fill = n * value &amp;gt; 0)) + geom_col(show.legend = FALSE) + xlab(&quot;Words perceded by not&quot;) + ylab(&quot;Sentiment score * Number of Occurences&quot;) + ggtitle(&quot;Polar Sentiment of Words Preceded by Not&quot;) + coord_flip()Negation BigramHere we can see that words such as “help” is preceded by “not” a lot in the text which has negative sentiments but it is counted as positive sentiment if we use 1 word in computing sentiment value.Negation Bigram NetworkThe negation bigram network is similar to polar sentiment graph, but the difference here is instead of considering the case for “not” only, we add more negation words(“not”, “no”, “never”, “without”) and plot the network graph to see the relationship between negation words and the negated words.negation_words = c(&quot;not&quot;, &quot;no&quot;, &quot;never&quot;, &quot;without&quot;)negation_bigrams = bigrams_seperated %&amp;gt;% filter(word1 %in% negation_words) %&amp;gt;% inner_join(get_sentiments(&quot;afinn&quot;), by=c(word2=&quot;word&quot;)) %&amp;gt;% count(word1, word2, value, sort = TRUE) %&amp;gt;% mutate(contribution = n *value) %&amp;gt;% arrange(desc(abs(contribution))) %&amp;gt;% group_by(word1) %&amp;gt;% slice(seq_len(20)) %&amp;gt;% arrange(word1, desc(contribution)) %&amp;gt;% ungroup()bigram_graph = negation_bigrams %&amp;gt;% graph_from_data_frame() # from &#39;igraph&#39;a = grid::arrow(type =&quot;closed&quot;, length = unit(.15, &quot;inches&quot;))ggraph(bigram_graph, layout=&#39;fr&#39;)+ geom_edge_link(alpha=.25)+ geom_edge_density(aes(fill=value))+ geom_node_point(color=&quot;purple1&quot;, size=1) + geom_node_text(aes(label=name), repel=TRUE)+ theme_void()+theme(legend.position = &#39;none&#39;, plot.title = element_text(hjust=0.5)) + ggtitle(&quot;Negation Bigram Network&quot;)Negation Bigram NetworkProblems with get_sentimentsBack to GoalsWew we have done a lot huh! Now let’s look back our goals and answer them all! What are the most frequent words used? “Winston” with 440 frequency Which are the positive and negative words prevalent in his book? Positive: “kind”, “brother”, “feeling”, “word”, “ministry” Negative: “war”, “pain”, “feeling”, “small”, “words” What are the overall sentiments expressed in his book? The book is written in negative tone. Which are the top words used to describe different emotions? Anger: “feeling”, “words” Anticipation: “time”, “thought” Disgust: “feeling”, “death” Fear: “war”, “pain” Joy: “kind”, “feeling” Sadness: “pain”, “feeling” Surprise: “feeling”, “suddenly” Trust: “kind”, “brother” ConclusionWe have used a lot of library to do the task. First we scapes the text data from the Internet, then we store them in the local storage and turn them into data frame.We also use syuzhet library to get the sentiment score using different lexicons, namely bing, nrc and afinn.We plotted some graphs to perform text analysis, below are the graphs that we’ve plotted: Word Cloud Sentiment Scores Words to Express Different Emotions and Sentiments Words Contributed to Sentiment Scores by Parts Mood Ring Polar Sentiment Preceded by NOT Negation Bigram NetworkResources The Data Science of “Someone Like You” or Sentiment Analysis of Adele’s Songs Sentiment Analysis of Colorado Flood Tweets in R Text mining and word cloud fundamentals in R Sentiment analysis with tidy data Tidy Sentiment Analysis in R" }, { "title": "Social Engagement?", "url": "/junnn/posts/Social-Engagement-1/", "categories": "Social Engagement", "tags": "social-engagement", "date": "2022-04-06 13:19:21 +0000", "snippet": "Start of the Journey ✨For this sem, I have taken Social Engagement. It’s an interesting course, all of the class have to work together to plan and execute an event. This year, we will be collaborated with Meta (Yes! Meta Facebok!) to plan a 4-module event. I am interested to develop the website and managing social media so I joined the publicity department. So far, I really like our department’s environment, all of the members are very responsible and caring.Our Job Scopes 🔥 Create and manage Instagram and Facebook account for the program Prepare articles and news for the program Prepare the photo book after the programFirst Task! 🤩The first thing we did after assigning job was a discussion to come out with the features of the website. Then, we decided to involve every one in the designing so we open it to other classmates. I was quite surprise as we got 3 design from our talented classmates 💖(Chen Ching Yen, Sam Wei Hong, Janice &amp;amp; Jasmine). Love yall 🥰 !!! Ching Yen even coded the website in just a week! Wow! Shiao Yin(from Publicity too) and I also designed one. After receiving their desing, we intergrated some of their ideas into our design.Part of Ching Yen’s WebsitePart of Wei Hong’s DesignPart of Janice &amp;amp; Jasmine’s WebsiteLanding Page of Our Final DesignWhat’s Next?Since the opening ceremony is just around the corner, we’ll be starting to develop our website and hopefully we can make it in time!" } ]
